{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Challenge 2: Embedding chunks, create Azure AI search index**\n",
        "\n",
        "### Embeddings Overview\n",
        "An embedding is a special format of data representation that can be easily utilized by machine learning models and algorithms. The embedding is an information dense representation of the semantic meaning of a piece of text. Each embedding is a vector of floating-point numbers, such that the distance between two embeddings in the vector space is correlated with semantic similarity between two inputs in the original format. For example, if two texts are similar, then their vector representations should also be similar.\n",
        "\n",
        "Different Azure OpenAI embedding models are specifically created to be good at particular tasks:\n",
        "\n",
        "- Similarity embeddings are good at capturing semantic similarity between two or more pieces of text.\n",
        "- Text search embeddings help find which long document is relevant to a short query.\n",
        "- Code search embeddings are useful for embedding code snippets and embedding nature language search queries.\n",
        "\n",
        "Embeddings make it easier to do machine learning on large inputs representing words by capturing the semantic similarities in a vector space. Therefore, we can use embeddings to if two text chunks are semantically related or similar, and inherently provide a score to assess similarity.\n",
        "\n",
        "### Cosine Similarity\n",
        "A previously used approach to match similar documents was based on counting maximum number of common words between documents. This is flawed since as the document size increases, the overlap of common words increases even if the topics differ. Therefore cosine similarity is a better approach.\n",
        "\n",
        "Mathematically, cosine similarity measures the cosine of the angle between two vectors projected in a multi-dimensional space. This is beneficial because if two documents are far apart by Euclidean distance because of size, they could still have a smaller angle between them and therefore higher cosine similarity.\n",
        "\n",
        "The Azure OpenAI embeddings rely on cosine similarity to compute similarity between documents and a query.\n",
        "\n",
        "## Let start the challenge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1716772108890
        }
      },
      "outputs": [],
      "source": [
        "# Import required libraries  \n",
        "import os  \n",
        "import json  \n",
        "from openai import AzureOpenAI, DefaultHttpxClient\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "from azure.core.credentials import AzureKeyCredential  \n",
        "from azure.search.documents import SearchClient  \n",
        "from azure.search.documents.indexes import SearchIndexClient  \n",
        "from azure.search.documents.indexes.models import (  \n",
        "    SearchIndex,  \n",
        "    SearchField,  \n",
        "    SearchFieldDataType,  \n",
        "    SimpleField,  \n",
        "    SearchableField,  \n",
        "    SearchIndex,  \n",
        "    SemanticConfiguration,  \n",
        "    PrioritizedFields,  \n",
        "    SemanticField,  \n",
        "    SearchField,  \n",
        "    SemanticSettings,  \n",
        "    VectorSearch,\n",
        "    HnswVectorSearchAlgorithmConfiguration,\n",
        ")\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1716772110897
        }
      },
      "outputs": [],
      "source": [
        "# Configure environment variables  \n",
        "load_dotenv(find_dotenv('credential.env'), override=True)\n",
        "\n",
        "# Azure AI Search\n",
        "service_endpoint = os.environ['AZURE_AI_SEARCH_ENDPOINT']\n",
        "key = os.environ['AZURE_AI_SEARCH_KEY']\n",
        "index_name = os.environ['AZURE_AI_SEARCH_INDEX_NAME']\n",
        "credential = AzureKeyCredential(key)\n",
        "\n",
        "#Azure OpenAI\n",
        "client = AzureOpenAI(\n",
        "  api_key = os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
        "  azure_endpoint = os.environ['AZURE_OPENAI_API_ENDPOINT'],\n",
        "  api_version = os.environ['AZURE_OPENAI_API_VERSION'],\n",
        "  http_client = DefaultHttpxClient(verify=False)\n",
        ")\n",
        "embedding_model = os.environ['EMBEDDING_MODEL_NAME']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Declare useful method\n",
        "def check_and_create_folder(folder_name):\n",
        "    if not os.path.exists(folder_name):\n",
        "        os.makedirs(folder_name)\n",
        "        print(f\"The folder '{folder_name}' has been created.\")\n",
        "    else:\n",
        "        print(f\"The folder '{folder_name}' already exists.\")\n",
        "\n",
        "def print_error_message(message, prefix_message='Error: '):\n",
        "    print(f\"\\033[1;31m{prefix_message}\\033[0m{message}\")\n",
        "\n",
        "def print_warning_message(message, prefix_message='Warning: '):\n",
        "    print(f\"\\033[1;33m{prefix_message}\\033[0m{message}\")\n",
        "    \n",
        "def print_success_message(message, prefix_message='Success: '):\n",
        "    print(f\"\\033[1;32m{prefix_message}\\033[0m{message}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [Step4] Generate embeddings of chunked document\n",
        "In this step, it will read the chunked documents, generate OpenAI embeddings and export to a format to insert your Azure AI Search index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1716772112854
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def generate_embeddings(text):\n",
        "    response = client.embeddings.create(input=text, model=embedding_model)\n",
        "    return response.data[0].embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716772260937
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "print_warning_message(\"Generate embeddings of chunked document\", \">>>[STEP4] \")\n",
        "\n",
        "# Set the local folder name for document intelligence output\n",
        "# Check if the folder exists\n",
        "check_and_create_folder(\"chunked_document_vector\")\n",
        "\n",
        "# Create embeddings on field \"Content\" using Azure OpenAI embedding model        \n",
        "for file in Path().glob(\"chunked_document/*.json\"):\n",
        "    input_data = json.loads(file.read_text())\n",
        "    content = input_data['content']\n",
        "    content_embeddings = generate_embeddings(content)\n",
        "    input_data['contentVector'] = content_embeddings\n",
        "    with open(f\"chunked_document_vector/{file.name}\", \"w\") as f:\n",
        "        json.dump(input_data, f)\n",
        "    print_success_message(f'Embedding chunked document {file.name}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [Check Point] Review embedded chunked document in \"chunked_document_vector\" folder"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [Step5] Create Azure AI Search index\n",
        "Create the search index schema and vector search configuration:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716772286478
        }
      },
      "outputs": [],
      "source": [
        "print_warning_message(\"Create Azure AI Search index\", \">>>[STEP5] \")\n",
        "\n",
        "# Create a search index\n",
        "index_client = SearchIndexClient(endpoint=service_endpoint, credential=credential)\n",
        "fields = [\n",
        "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
        "    SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
        "    SearchableField(name=\"category\", type=SearchFieldDataType.String, filterable=True),\n",
        "    SearchableField(name=\"sourcepage\", type=SearchFieldDataType.String),\n",
        "    SearchableField(name=\"sourcefile\", type=SearchFieldDataType.String),\n",
        "    SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
        "                searchable=True, vector_search_dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
        "]\n",
        "\n",
        "vector_search = VectorSearch(\n",
        "    algorithm_configurations=[\n",
        "        HnswVectorSearchAlgorithmConfiguration(\n",
        "            name=\"my-vector-config\",\n",
        "            kind=\"hnsw\",\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "semantic_config = SemanticConfiguration(\n",
        "    name=\"my-semantic-config\",\n",
        "    prioritized_fields=PrioritizedFields(\n",
        "        prioritized_content_fields=[SemanticField(field_name=\"content\")]\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create the semantic settings with the configuration\n",
        "semantic_settings = SemanticSettings(configurations=[semantic_config])\n",
        "\n",
        "# Create the search index with the semantic settings\n",
        "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search,\n",
        "                    semantic_settings=semantic_settings)\n",
        "result = index_client.create_or_update_index(index)\n",
        "print_success_message(f'Index name: \"{result.name}\" is created')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [Step6] Upload embedded chunk documents to Azure AI Index\n",
        "\n",
        "Insert text and upload embeddings into an index by adding texts and metadata from the JSON data to the vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716772304025
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "print_warning_message(\"Upload embedded chunk documents to Azure AI Index\", \">>>[STEP6] \")\n",
        "\n",
        "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)\n",
        "        \n",
        "for file in Path().glob(\"chunked_document_vector/*.json\"):\n",
        "    input_data = json.loads(file.read_text())\n",
        "    result = search_client.upload_documents(input_data)\n",
        "    print_success_message(f\"Uploaded embedded chunk: {file.name} to {index_name} index.\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [Check Point] Navigate to Azure AI Search in Azure Portal, review your index and try to search using \"Search Explorer\" inside your index."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
